{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaDB Features â†’ ML/VectorBT Example\n",
    "\n",
    "This notebook shows how to:\n",
    "1. Export features from TimescaleDB to Parquet\n",
    "2. Load features for ML training\n",
    "3. Use features with VectorBT for backtesting\n",
    "4. Build a simple trading strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('../scripts')\n",
    "from export_features import FeaturesExporter\n",
    "\n",
    "# Optional: VectorBT for backtesting\n",
    "try:\n",
    "    import vectorbt as vbt\n",
    "    VBT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"VectorBT not installed. Backtesting features will be limited.\")\n",
    "    VBT_AVAILABLE = False\n",
    "\n",
    "# Optional: ML libraries\n",
    "try:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import classification_report\n",
    "    ML_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn not installed. ML examples will be limited.\")\n",
    "    ML_AVAILABLE = False\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Export Features from AlphaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the exporter\n",
    "exporter = FeaturesExporter(output_dir=\"../data/features\")\n",
    "\n",
    "# Check what data is available\n",
    "date_range = exporter.get_date_range()\n",
    "available_symbols = exporter.get_available_symbols()\n",
    "\n",
    "print(f\"Available symbols: {available_symbols}\")\n",
    "print(f\"Data range: {date_range['earliest_date']} to {date_range['latest_date']}\")\n",
    "print(f\"Total records: {date_range['total_records']:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export ML-ready features (last 30 days)\n",
    "ml_filepath = exporter.export_ml_ready_features(\n",
    "    symbols=['BTC/USDT'], \n",
    "    days=30,\n",
    "    target_periods=[1, 5, 15]  # 1min, 5min, 15min targets\n",
    ")\n",
    "\n",
    "print(f\"ML features exported to: {ml_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export VectorBT-ready format\n",
    "if VBT_AVAILABLE:\n",
    "    vbt_filepath = exporter.export_vectorbt_ready(\n",
    "        symbol='BTC/USDT',\n",
    "        days=90\n",
    "    )\n",
    "    print(f\"VectorBT data exported to: {vbt_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML-ready features\n",
    "df = pd.read_parquet(ml_filepath)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df['bucket'].min()} to {df['bucket'].max()}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature overview\n",
    "feature_cols = [col for col in df.columns if not col.startswith('target_') and col not in ['bucket', 'symbol']]\n",
    "target_cols = [col for col in df.columns if col.startswith('target_')]\n",
    "\n",
    "print(f\"Features ({len(feature_cols)}): {feature_cols[:10]}...\")  # Show first 10\n",
    "print(f\"Targets ({len(target_cols)}): {target_cols}\")\n",
    "\n",
    "# Basic statistics\n",
    "df[feature_cols[:5]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot key features over time\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('BTC Features Over Time', fontsize=16)\n",
    "\n",
    "# Price\n",
    "axes[0,0].plot(pd.to_datetime(df['bucket']), df['close_price'])\n",
    "axes[0,0].set_title('BTC Price')\n",
    "axes[0,0].set_ylabel('Price ($)')\n",
    "\n",
    "# Volatility\n",
    "axes[0,1].plot(pd.to_datetime(df['bucket']), df['hl_range_pct'] * 100)\n",
    "axes[0,1].set_title('Intrabar Volatility')\n",
    "axes[0,1].set_ylabel('HL Range (%)')\n",
    "\n",
    "# VWAP Gap\n",
    "axes[1,0].plot(pd.to_datetime(df['bucket']), df['vwap_gap'])\n",
    "axes[1,0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1,0].set_title('VWAP Gap')\n",
    "axes[1,0].set_ylabel('Gap ($)')\n",
    "\n",
    "# Volume\n",
    "axes[1,1].plot(pd.to_datetime(df['bucket']), df['volume'])\n",
    "axes[1,1].set_title('Volume')\n",
    "axes[1,1].set_ylabel('Volume')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation matrix\n",
    "core_features = ['hl_range_pct', 'vwap_gap', 'parkinson_vol', 'return_5m', 'vol_ma_60', 'close_ma_60']\n",
    "correlation_matrix = df[core_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple ML Model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ML_AVAILABLE:\n",
    "    # Prepare data for ML\n",
    "    feature_cols = [col for col in df.columns \n",
    "                   if not col.startswith(('target_', 'bucket', 'symbol')) \n",
    "                   and col not in ['vol_regime']  # Skip categorical for now\n",
    "                   ]\n",
    "    \n",
    "    # Use 5-minute return direction as target\n",
    "    target_col = 'target_5m_sign'\n",
    "    \n",
    "    # Remove rows with NaN values\n",
    "    ml_data = df[feature_cols + [target_col]].dropna()\n",
    "    \n",
    "    X = ml_data[feature_cols]\n",
    "    y = ml_data[target_col]\n",
    "    \n",
    "    print(f\"ML dataset shape: {X.shape}\")\n",
    "    print(f\"Target distribution: {y.value_counts()}\")\n",
    "    \n",
    "    # Split data (time-aware split)\n",
    "    split_idx = int(len(X) * 0.8)\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "    \n",
    "    # Train simple Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=feature_importance.head(15), x='importance', y='feature')\n",
    "    plt.title('Top 15 Feature Importances')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "else:\n",
    "    print(\"Scikit-learn not available. Skipping ML example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VectorBT Backtesting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VBT_AVAILABLE:\n",
    "    # Load VectorBT-ready data\n",
    "    vbt_data = pd.read_parquet(vbt_filepath)\n",
    "    \n",
    "    print(f\"VectorBT data shape: {vbt_data.shape}\")\n",
    "    print(f\"Columns: {list(vbt_data.columns)}\")\n",
    "    print(f\"Index: {vbt_data.index.name} from {vbt_data.index.min()} to {vbt_data.index.max()}\")\n",
    "    \n",
    "    # Strategy 1: Volatility Breakout\n",
    "    # Buy when volatility > 60-period average AND VWAP gap > 0\n",
    "    vol_threshold = vbt_data['hl_range_pct'].rolling(60).mean()\n",
    "    vwap_threshold = 0\n",
    "    \n",
    "    buy_signals = (\n",
    "        (vbt_data['hl_range_pct'] > vol_threshold) & \n",
    "        (vbt_data['vwap_gap'] > vwap_threshold)\n",
    "    )\n",
    "    \n",
    "    sell_signals = (\n",
    "        (vbt_data['hl_range_pct'] < vol_threshold) | \n",
    "        (vbt_data['vwap_gap'] < vwap_threshold)\n",
    "    )\n",
    "    \n",
    "    # Run backtest\n",
    "    portfolio = vbt.Portfolio.from_signals(\n",
    "        vbt_data['close'], \n",
    "        buy_signals, \n",
    "        sell_signals,\n",
    "        fees=0.001,  # 0.1% fees\n",
    "        freq='1T'    # 1-minute frequency\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Volatility Breakout Strategy Results ===\")\n",
    "    print(f\"Total Return: {portfolio.total_return():.2%}\")\n",
    "    print(f\"Sharpe Ratio: {portfolio.sharpe_ratio():.2f}\")\n",
    "    print(f\"Max Drawdown: {portfolio.max_drawdown():.2%}\")\n",
    "    print(f\"Win Rate: {portfolio.trades.win_rate:.2%}\")\n",
    "    print(f\"Total Trades: {portfolio.trades.count}\")\n",
    "    \n",
    "    # Plot results\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Price and signals\n",
    "    axes[0].plot(vbt_data.index, vbt_data['close'], label='BTC Price', alpha=0.7)\n",
    "    buy_mask = buy_signals & ~buy_signals.shift(1, fill_value=False)\n",
    "    sell_mask = sell_signals & ~sell_signals.shift(1, fill_value=False)\n",
    "    \n",
    "    axes[0].scatter(vbt_data.index[buy_mask], vbt_data['close'][buy_mask], \n",
    "                   color='green', marker='^', s=50, label='Buy')\n",
    "    axes[0].scatter(vbt_data.index[sell_mask], vbt_data['close'][sell_mask], \n",
    "                   color='red', marker='v', s=50, label='Sell')\n",
    "    axes[0].set_title('BTC Price with Trading Signals')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Portfolio value\n",
    "    axes[1].plot(vbt_data.index, portfolio.value())\n",
    "    axes[1].set_title('Portfolio Value')\n",
    "    axes[1].set_ylabel('Portfolio Value ($)')\n",
    "    \n",
    "    # Features used in strategy\n",
    "    axes[2].plot(vbt_data.index, vbt_data['hl_range_pct'] * 100, label='Volatility %', alpha=0.7)\n",
    "    axes[2].plot(vbt_data.index, vol_threshold * 100, label='Vol Threshold', linestyle='--')\n",
    "    axes[2].set_title('Volatility Signal')\n",
    "    axes[2].set_ylabel('Volatility (%)')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"VectorBT not available. Skipping backtesting example.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Data for External Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export different formats for various use cases\n",
    "\n",
    "# 1. Raw features for custom ML pipelines\n",
    "raw_filepath = exporter.export_features(\n",
    "    symbols=['BTC/USDT', 'ETH/USDT'],\n",
    "    start_date=pd.Timestamp.now() - pd.Timedelta(days=7)  # Last week\n",
    ")\n",
    "\n",
    "print(f\"Raw features exported: {raw_filepath}\")\n",
    "\n",
    "# 2. Quick CSV export for Excel/R users\n",
    "csv_path = Path(raw_filepath).with_suffix('.csv')\n",
    "raw_data = pd.read_parquet(raw_filepath)\n",
    "raw_data.to_csv(csv_path, index=False)\n",
    "print(f\"CSV version: {csv_path}\")\n",
    "\n",
    "# 3. Summary statistics\n",
    "summary = raw_data.groupby('symbol').agg({\n",
    "    'close_price': ['mean', 'std', 'min', 'max'],\n",
    "    'hl_range_pct': ['mean', 'std', 'max'],\n",
    "    'volume': ['mean', 'sum'],\n",
    "    'is_green': 'mean'  # Win rate\n",
    "})\n",
    "\n",
    "print(\"\\n=== Weekly Summary Statistics ===\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "This notebook showed you how to:\n",
    "\n",
    "âœ… **Export features** from AlphaDB to Parquet files  \n",
    "âœ… **Load and explore** the feature data  \n",
    "âœ… **Build ML models** using the engineered features  \n",
    "âœ… **Backtest strategies** with VectorBT  \n",
    "âœ… **Export data** in various formats  \n",
    "\n",
    "### What you can do next:\n",
    "\n",
    "1. **Scale up ML models**: Try XGBoost, LightGBM, or neural networks\n",
    "2. **Advanced feature engineering**: Create more sophisticated technical indicators\n",
    "3. **Multi-symbol strategies**: Build portfolio optimization models\n",
    "4. **Real-time trading**: Use FastAPI to serve model predictions\n",
    "5. **Risk management**: Add position sizing and drawdown controls\n",
    "\n",
    "### Production workflow:\n",
    "```bash\n",
    "# Daily feature export\n",
    "python scripts/export_features.py --incremental --hours 24\n",
    "\n",
    "# Weekly ML model retraining  \n",
    "python scripts/export_features.py --ml-ready --days 30\n",
    "\n",
    "# Monthly full backtest\n",
    "python scripts/export_features.py --vectorbt --days 90\n",
    "```\n",
    "\n",
    "Your AlphaDB feature engineering system is now **production-ready** for quantitative research! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
